\addvspace {10pt}
\contentsline {figure}{\numberline {1.1}{\ignorespaces Schematic of a 4$f$ optical system}}{3}{figure.1.1}
\addvspace {10pt}
\contentsline {figure}{\numberline {2.1}{\ignorespaces Single-shot color Differential Phase Contrast (cDPC) microscopy. a) Installation in Nikon TE300 microscope condenser turret. b) CAD model and image of fabricated cDPC insert.c) Optical schematic of a brightfield microscope with a cDPC color filter placed at the back focal plane of the condenser in K\"{o}hler configuration. d) Reconstruction: the captured color image is separated into its RGB components, which are then used to recover two unknowns (amplitude and phase) via a well-posed linear deconvolution. The sample is a micro-lens array (Fresnel Technologies 605). }}{12}{figure.2.1}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Transfer functions for amplitude and phase contrast in each cDPC color channel. Left: Spectral contribution of each illumination filter as captured by the camera's Bayer pattern. The following columns show the components of the amplitude and phase transfer functions in the spatial frequency domain and the source represented in each image. Bottom row: sum of each column, representing the calibrated and scaled source and the total coverage of amplitude and phase transfer functions, respectively. }}{13}{figure.2.2}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Experimental comparison of single-shot cDPC with monochromatic DPC and through-focus phase retrieval methods. (Left) Source patterns. (Middle) Raw camera measurements. (Right) Recovered optical field. DPC methods (partially coherent) were acquired using a 20$\times $ 0.4 NA objective lens, while through-focus images (spatially coherent) were captured using 60$\times $ 0.8 NA, in order to ensure equal resolution in all cases.}}{14}{figure.2.3}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Phase and amplitude reconstructions for various samples and magnifications. (First column) Micro-lens array, 4x 0.1 NA. (Second column) Wild-type c. elegans, 10x 0.25 NA. (Third column) HEK 293T cells, 20$\times $ 0.4 NA). (Fourth column) MCF7 cells, 20$\times $ 0.4 NA.}}{16}{figure.2.4}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Experimental demonstration of motion blur reduction with cDPC vs. conventional DPC. The cDPC method results in significantly reduced motion blur artifacts due to its single-shot acquisition.}}{19}{figure.2.5}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Comparison of standard DIC and PhC images to their synthesized counterparts from cDPC. Ground truth DIC images were acquired using a 20x 0.75 NA objective and phase contrast images using a 20x 0.4 NA PhC objective. cDPC images were acquired using a 20x 0.4 NA objective and the filter insert.}}{20}{figure.2.6}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Motion blur real-space and Fourier space representations. In the case of a static object, the object is filtered by the optical transfer function (OTF), assuming incoherent illumination. With motion blur, an additional convolution with a blurring function $B(\mathaccentV {vec}17E{r})$ causes attenuation in the frequency domain which acts as a cascaded linear filter on the object. In the case of coded blur, the transfer function is attenuated much less than in the conventional blur case. The colorbars are constant for real and fourier domain images respectively.}}{24}{figure.2.7}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Motion blurring kernels for 1D motion in the Fourier Domain. \textbf {Left Column:} Unblurred absorption (top) and phase (bottom) transfer functions. \textbf {$2^{nd}$ Column}: Middle: Fourier transform of constant (non-coded) blur kernel. The top and bottom spectra in this column are the product of the unblurred transfer function and this center spectrum. \textbf {$3^{rd}$ Column}: Blurred transfer function spectra for temporal coding which does not consider WOTF structure. \textbf {$4^{th}$ Column}: Blurred transfer function spectra for temporal coding which emphasizes low and high frequencies based on WOTF structure.}}{26}{figure.2.8}
\contentsline {figure}{\numberline {2.9}{\ignorespaces Simulation results for phase retrieval from blurred images. \textbf {Top Row}: Phase and amplitude retrieval of a stationary sample. This serves as our best-case reconstruction for the blurred images. \textbf {Second Row}: Phase and amplitude retrieval of a blurred sample using constant illumination. This is the degenerate solution. \textbf {Third Row}: Deblur using a coded blur kernel as in the previous methods. The result improves significantly over the constant illumination case, but is still missing features in phase. \textbf {Fourth Row}: Deblur using our coded kernels}}{28}{figure.2.9}
\contentsline {figure}{\numberline {2.10}{\ignorespaces Experimental setup for motion deblurring. The tri-color LED array provides fast illumination coding in time, angle, and color. The LED array can be programmed dynamically using a Teensy micro-controller and has a maximum update speed of approximately 250 Hz. The LED array is synchronized with the linear motion stage and camera in hardware to provide precise system synchronization.}}{29}{figure.2.10}
\contentsline {figure}{\numberline {2.11}{\ignorespaces Experimental results for motion deblur of a moving sample (Fresnel Technologies 605 micro-lens array).}}{30}{figure.2.11}
\addvspace {10pt}
\contentsline {figure}{\numberline {3.1}{\ignorespaces {Computational CellScope.} {a).} Device observing a sample using a Nexus 4 smartphone. {b).} Optical schematic of the CellScope device with our custom-made domed LED illuminator. {c).} CAD assembly of the dome. {d).} Assembled dome and control circuitry.}}{32}{figure.3.1}
\contentsline {figure}{\numberline {3.2}{\ignorespaces { Domed LED Illuminator.}{a)} Illumination pattern used to acquire dark field images with a 0.25 NA objective. {b)} Illumination pattern used to synthesize differential phase contrast images with a 0.25 NA objective. {c)} Illustration of the arbitrary illumination patterning capabilities of the device. {d)} Normalized mean pixel intensities measured at the sensor for the planar and domed arrays. Intensity decreases as a function of angle in both cases, but much more strongly in the case of the planar geometry. Values were normalized to the central LED's brightness in both cases. {e)} Visual comparison of a planar LED array with a domed array. Since the intensity of a spherical wave drops as a function of the inverse square of radius, the illumination at the sample depends on the distance between the LEDs and the sample. In the planar case (left), LED distance $r$ increases as a function of illumination angle, causing weaker illumination at higher angles. A domed LED array (right) eliminates this variation ($r$ is constant). {f)} Plot illustrating the relative objective NA for several common magnifications, as compared to our dome's LED placement (small black circles). {g)} Normalized measured intensity falloff as a function of angle relative to the optical axis for the domed and planar LED arrays. Falloff is proportional to $\qopname \relax o{cos}{\theta }$ for the domed geometry and $\sim \qopname \relax o{cos}^4{\theta }$ for the planar geometry. Black lines are $\qopname \relax o{cos}{\theta }$ and $\qopname \relax o{cos}^4{\theta }$ fits for the domed and planar geometries, respectively. The domed geometry exhibits significant improvements in intensity at large angles of illumination. }}{34}{figure.3.2}
\contentsline {figure}{\numberline {3.3}{\ignorespaces {Image Results Compared to a Standard Microscope.} Computational CellScope acquires brightfield and darkfield images of similar quality to a standard upright microscope (Nikon TE300) without the use of hardware inserts. Additionally, it enables phase imaging using Differential Phase Contrast (DPC), which contains similar information to standard phase contrast imaging, and can be inverted to obtain quantitative phase of the sample (bottom row). Differences in color shades are caused by the relative differences in hue of the halogen lamp and the white LEDs. Note the additional dark features in DIC results, as compared to DPC, illustrating mixing of phase and absorption information in DIC. In the rightmost column, we show images for an unstained transparent sample, illustrating the utility of phase imaging methods for label-free imaging. }}{36}{figure.3.3}
\contentsline {figure}{\numberline {3.4}{\ignorespaces {Digital refocusing on the Computational CellScope.} Comparison of digital refocusing to physical refocusing on a commercial microscope (Nikon TE300) of a house fly wing sample (AmScope PS200) with a 10$\times $ objective. Digitally refocused phase contrast images are also computed for both vertical and horizontal phase derivatives at different focus depths.}}{39}{figure.3.4}
\contentsline {figure}{\numberline {3.5}{\ignorespaces {Android Application Workflow.} {a).} Schematic of streaming multi-contrast LED patterns. Here we vary the LED pattern in time and acquire and process images on the smartphone, producing a streaming multi-contrast display of a sample without any further post-processing. The user can touch any image to zoom in and stream an individual image. Total cycle time is 2.3 seconds. {b).} Overview of workflow for digital refocusing mode. Table shows example processing and acquisition times for a typical dataset reconstruction. Axial Resolution is determined by the range of illumination angles sampled (defined by the objective NA). The number of z-steps were chosen such that refocus blur does not exceed 20 pixels. Processing and acquisition time can be reduced by selecting fewer refocus planes or by sparsely sampling LEDs, trading axial resolution for faster acquisition time.}}{41}{figure.3.5}
\addvspace {10pt}
