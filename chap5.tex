\chapter{Conclusion}
This thesis presents several computational imaging systems which use novel combinations of both hardware and software to image samples at high-speed, low cost, and in a portable system. Taken together, these methods illustrate the capabilities of a computational imaging system, and offer evidence of the impact these systems could have on the broader optical imaging community.

In Chapter 2, a single-shot method for quantitative phase and amplitude imaging which uses partially-coherent (angle-coded) multiplexed color illumination to recover the linearized optical field from a single deconvolution was presented. Our hardware requirements are simple, inexpensive, and compatible with most commercial microscopes through of the use of a color camera and a simple color filter insert placed at the back focal plane of the condenser lens, the same position as many removable phase contrast annulus rings. Unlike phase contrast and DIC, our method does not require special objectives or prisms, which reduces our hardware costs to that of the 3D printed filter itself. In addition, we can use our quantitative phase and amplitude methods to synthesize phase contrast and DIC images digitally, matching the functionality of existing phase imaging systems at a fraction of the cost.

In Chapter 3, a motion deblurring algorithm which uses time-coded active illumination to recover the complete optical field (phase and absorption) of a moving sample was presented. Our results show that by taking the OTF or WOTF of a system into account when designing blurring intensities, one can improve reconstruction quality of a deblurred image significantly. Further, we showed experimentally that motion deblur and quantitative phase retrieval can be applied together, and that our knowledge of the OTF improves reconstruction quality. This work did not consider non-linear kernels or unknown kernels, but the extension to this domain would be possible provided appropriate constraints were applied to the kernel shape and structure. An additional direction of interest is the blind deconvolution of motion kernels from a single blurred image. Since the WOTF inversion from a color image is over-determined, there is hope of recovering blur kernels using this over-determined information. A weakness of this method is in the need for precise alignment and synchronization of the stage, microscope, and illuminator. Blind deconvolution could account for small mis-alignments of the sample by solving for the blur kernel with little a-priori information.

In Chapter 4, a programmable domed LED array attachment and software for the CellScope mobile microscopy platform was demonstrated, enabling computational illumination techniques in a portable and affordable package. We demonstrated that this device allows multi-contrast imaging in near real-time, darkfield imaging without the cost or complexity of mechanical inserts, and phase imaging methods for label-free imaging of transparent cells and microorganisms in the field. Since our LED array is programmable, we are able to switch between contrast modes in real-time, simply by changing the illumination patterning. We currently stream at a frame rate of approximately 0.43 frames per second. Additionally, we use lightfield methods to enable digital refocusing of samples and have shown that this device is capable of refocusing samples across a 400$\mu$m range (at NA 0.25) with axial resolution of a few microns. All information needed to fabricate the Computational Cellscope dome, including the parts list, CAD designs, and software, are publicly available under the BSD open source license at: \begin{verbatim}www.laurawaller.com/OpenSource\end{verbatim}.

\section{Proposed Future Work}

In portable microscopy, future work will utilize similar LED array hardware, but add new imaging modes to our Computational CellScope device for quantitative 3D phase and super-resolution imaging. 3D imaging with tomographic inversions of both phase and amplitude information should be possible using similar datasets and more sophisticated algorithms~\cite{tian20153d}, if they can be adapted to mobile phone post-processing. One exciting potential extension of the device is to implement Fourier Ptychography~\cite{Zheng2013,Dong:14,Tian2014} or other super-resolution methods~\cite{Zhu2011,Greenbaum17122014} for achieving very wide field of view in conjunction with resolution well beyond the diffraction limit of the objective. These methods can also be combined with light field refocusing to obtain 3D stacks of both phase and intensity with large space-bandwidth product~\cite{tian20153d}. Our dome has been designed with these further applications in mind, so that these new capabilities can be added to our Computational CellScope platform as entirely software-side improvements. Thus, they may be deployed to existing devices via software updates over a cellular data network.

In addition, I hope to explore combinations of motion deblurring and portable microscopy for high-throughput imaging applications. Due to the calibration requirements of motion deblurring, it will be important to develop auto-calibration procedures to account for stage motion error and illumination mis-alignment to produce satisfactory images. This project can be formulated as a blind deconvolution problem, but I hope to incorporate non-linear terms into the calibration procedure to help improve results. In addition, I hope to combine these methods with high-throughput Fourier-Ptychographic methods in order to enable extreme high-throughput imaging, potentially into gigapixel scales.

\section{Acknowledgements}
I would like to thank Professor Laura Waller for providing careful guidance and support, especially during my first year in graduate school. I would also like to thank my entire lab for countless useless discussions. In addition, I would like to thank all professors, Post-Docs, graduate students, and undergraduate students at UC Berkeley who helped produce work which led to this thesis: Prof. Neil Switz, Prof. Daniel Fletcher, Prof. Lei Tian, Mike Dâ€™Ambrosio, Michael Chen, Jared Rulison, Hurshal Patel, Nitin Sadras, Aditya Gande, and Joel Whang.